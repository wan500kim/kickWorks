{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText Embedding Model 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [크롤링 데이터 병합]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Youtube_comments.csv 91281 228250\n",
      "./ilbe_comments.csv 136969 228250\n",
      "dataset.txt 5825 234075\n",
      "fword_list.txt 3577 237652\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "Youtube_path = \"./Youtube_comments.csv\"\n",
    "ilbe_path = \"./ilbe_comments.csv\"\n",
    "\n",
    "Comment_df = pd.DataFrame()\n",
    "\n",
    "df1 = pd.read_csv(Youtube_path, encoding=\"cp949\", header=None, names=[0])\n",
    "df2 = pd.read_csv(ilbe_path, encoding=\"cp949\", header=None, names=[0])\n",
    "            \n",
    "Comment_df = pd.concat([Comment_df, df1])\n",
    "Comment_df = pd.concat([Comment_df, df2])\n",
    "        \n",
    "print(Youtube_path, len(df1), len(Comment_df))\n",
    "print(ilbe_path, len(df2), len(Comment_df))\n",
    "\n",
    "# dataset.txt, fword_list.txt 넣기\n",
    "with open('dataset.txt', 'r', encoding='UTF8') as f:\n",
    "    dataset_list = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line == '' :\n",
    "            break\n",
    "        dataset_list.append(line.strip().split('|')[0])\n",
    "        i += 1\n",
    "    df3 = pd.Series(dataset_list)\n",
    "    Comment_df = pd.concat([Comment_df, df3])\n",
    "    print(\"dataset.txt\", i, len(Comment_df))\n",
    "\n",
    "with open('fword_list.txt', 'r', encoding='UTF8') as f:\n",
    "    dataset_list = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line == '' :\n",
    "            break\n",
    "        dataset_list.append(line)\n",
    "        i += 1\n",
    "    df4 = pd.Series(dataset_list)\n",
    "    Comment_df = pd.concat([Comment_df, df4])\n",
    "    print(\"fword_list.txt\", i, len(Comment_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [FastText input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219241\n"
     ]
    }
   ],
   "source": [
    "# 중복제거 결과: 237652 -> 219241\n",
    "Comment_df.drop_duplicates(inplace=True)\n",
    "print(len(Comment_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(\"[^ㄱ-ㅎㅏ-ㅣ가-힣0-9a-zA-Z ]\") # 특수문자 제거\n",
    "\n",
    "# 각 단어에 정규표현식 적용\n",
    "def clear_word(word):\n",
    "    word = re.sub(pattern, \"\", word)\n",
    "    return word\n",
    "\n",
    "Comment_df[0] = Comment_df.astype('str')\n",
    "Comment_df[0] = Comment_df[0].apply(lambda x: clear_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment_df.reset_index(inplace=True)\n",
    "Comment_df.drop('index', axis=1, inplace=True)\n",
    "Comment_df = Comment_df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅌㅔㄱㅅㅡㄱㅌㅡㄱ\n"
     ]
    }
   ],
   "source": [
    "CHOSUNG_LIST = [u'ㄱ',u'ㄲ',u'ㄴ',u'ㄷ',u'ㄸ',u'ㄹ',u'ㅁ',u'ㅂ',u'ㅃ',u'ㅅ',u'ㅆ',u'ㅇ',u'ㅈ',u'ㅉ',u'ㅊ',u'ㅋ',u'ㅌ',u'ㅍ',u'ㅎ']\n",
    "JOONGSUNG_LISTS = [u'ㅏ',u'ㅐ',u'ㅑ',u'ㅒ',u'ㅓ',u'ㅔ',u'ㅕ',u'ㅖ',u'ㅗ',u'ㅘ',u'ㅙ',u'ㅚ',u'ㅛ',u'ㅜ',u'ㅝ',u'ㅞ',u'ㅟ',u'ㅠ',u'ㅡ',u'ㅢ',u'ㅣ']\n",
    "JONGSUNG_LIST = [u'_',u'ㄱ',u'ㄲ',u'ㄳ',u'ㄴ',u'ㄵ',u'ㄶ',u'ㄷ',u'ㄹ',u'ㄺ',u'ㄻ',u'ㄼ',u'ㄽ',u'ㄾ',u'ㄿ',u'ㅀ',u'ㅁ',u'ㅂ',u'ㅄ',u'ㅅ',u'ㅆ',u'ㅇ',u'ㅈ',u'ㅊ',u'ㅋ',u'ㅌ',u'ㅍ',u'ㅎ']\n",
    "\n",
    "# 자모분리기\n",
    "def kor_decompose(word, end_char=\"_\"):\n",
    "    result = []\n",
    "    \n",
    "    for char in word:\n",
    "        char_unicode = ord(char)\n",
    "        \n",
    "        if 0xD7A3 < char_unicode or char_unicode < 0xAC00:\n",
    "            result.append(char)\n",
    "            continue\n",
    "\n",
    "        chosung_index = int((((char_unicode - 0xAC00) / 28) / 21) % 19)\n",
    "        joongsung_index = int(((char_unicode - 0xAC00) / 28) % 21)\n",
    "        jongsung_index = int((char_unicode - 0xAC00) % 28)\n",
    "        \n",
    "        chosung = CHOSUNG_LIST[chosung_index]\n",
    "        joongsung = JOONGSUNG_LISTS[joongsung_index]\n",
    "        jongsung = JONGSUNG_LIST[jongsung_index+1]\n",
    "        \n",
    "        # 종성이 없을 경우 end_char로 대체\n",
    "        if jongsung_index == 0:\n",
    "            jongsung = end_char\n",
    "        \n",
    "        result.append(chosung)\n",
    "        result.append(joongsung)\n",
    "        result.append(jongsung)\n",
    "\n",
    "    return \"\".join(result)\n",
    "\n",
    "print(kor_decompose(\"테스트\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "03aab4221eabb5b090947200f58522311c44e3968445c8816a77822b1318598f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
