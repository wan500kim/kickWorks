{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FastText Embedding Model 생성**\n",
    "- 변형된 비속어를 학습하기 위해 char 단위로 학습하는 fasttext를 사용\n",
    "- 좌우 단어에 따라(문맥에 따라) 의미가 달라지는 경우도 뽑기 위함\n",
    "- 형태소가 적절히 분리되지 않는 경우가 많아 어절 단위로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [크롤링 데이터 병합]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Youtube_comments.csv 91281 228250\n",
      "./ilbe_comments.csv 136969 228250\n",
      "dataset.txt 5825 234075\n",
      "fword_list.txt 3577 237652\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "Youtube_path = \"./Youtube_comments.csv\"\n",
    "ilbe_path = \"./ilbe_comments.csv\"\n",
    "\n",
    "Comment_df = pd.DataFrame()\n",
    "\n",
    "df1 = pd.read_csv(Youtube_path, encoding=\"cp949\", header=None, names=[0])\n",
    "df2 = pd.read_csv(ilbe_path, encoding=\"cp949\", header=None, names=[0])\n",
    "            \n",
    "Comment_df = pd.concat([Comment_df, df1])\n",
    "Comment_df = pd.concat([Comment_df, df2])\n",
    "        \n",
    "print(Youtube_path, len(df1), len(Comment_df))\n",
    "print(ilbe_path, len(df2), len(Comment_df))\n",
    "\n",
    "# dataset.txt, fword_list.txt 넣기\n",
    "with open('dataset.txt', 'r', encoding='UTF8') as f:\n",
    "    dataset_list = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line == '' :\n",
    "            break\n",
    "        dataset_list.append(line.strip().split('|')[0])\n",
    "        i += 1\n",
    "    df3 = pd.Series(dataset_list)\n",
    "    Comment_df = pd.concat([Comment_df, df3])\n",
    "    print(\"dataset.txt\", i, len(Comment_df))\n",
    "\n",
    "with open('fword_list.txt', 'r', encoding='UTF8') as f:\n",
    "    dataset_list = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line == '' :\n",
    "            break\n",
    "        dataset_list.append(line)\n",
    "        i += 1\n",
    "    df4 = pd.Series(dataset_list)\n",
    "    Comment_df = pd.concat([Comment_df, df4])\n",
    "    print(\"fword_list.txt\", i, len(Comment_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [FastText input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219241\n"
     ]
    }
   ],
   "source": [
    "# 중복제거 결과: 237652 -> 219241\n",
    "Comment_df.drop_duplicates(inplace=True)\n",
    "print(len(Comment_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(\"[^ㄱ-ㅎㅏ-ㅣ가-힣0-9a-zA-Z ]\") # 특수문자 제거\n",
    "\n",
    "# 각 단어에 정규표현식 적용\n",
    "def clear_word(word):\n",
    "    word = re.sub(pattern, \"\", word)\n",
    "    return word\n",
    "\n",
    "Comment_df[0] = Comment_df.astype('str')\n",
    "Comment_df[0] = Comment_df[0].apply(lambda x: clear_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSUNG_LIST = [u'ㄱ',u'ㄲ',u'ㄴ',u'ㄷ',u'ㄸ',u'ㄹ',u'ㅁ',u'ㅂ',u'ㅃ',u'ㅅ',u'ㅆ',u'ㅇ',u'ㅈ',u'ㅉ',u'ㅊ',u'ㅋ',u'ㅌ',u'ㅍ',u'ㅎ']\n",
    "JOONGSUNG_LISTS = [u'ㅏ',u'ㅐ',u'ㅑ',u'ㅒ',u'ㅓ',u'ㅔ',u'ㅕ',u'ㅖ',u'ㅗ',u'ㅘ',u'ㅙ',u'ㅚ',u'ㅛ',u'ㅜ',u'ㅝ',u'ㅞ',u'ㅟ',u'ㅠ',u'ㅡ',u'ㅢ',u'ㅣ']\n",
    "JONGSUNG_LIST = [u'_',u'ㄱ',u'ㄲ',u'ㄳ',u'ㄴ',u'ㄵ',u'ㄶ',u'ㄷ',u'ㄹ',u'ㄺ',u'ㄻ',u'ㄼ',u'ㄽ',u'ㄾ',u'ㄿ',u'ㅀ',u'ㅁ',u'ㅂ',u'ㅄ',u'ㅅ',u'ㅆ',u'ㅇ',u'ㅈ',u'ㅊ',u'ㅋ',u'ㅌ',u'ㅍ',u'ㅎ']\n",
    "\n",
    "# 자모분리기\n",
    "def kor_decompose(word, end_char=\"_\"):\n",
    "    result = []\n",
    "    \n",
    "    for char in word:\n",
    "        char_unicode = ord(char)\n",
    "        \n",
    "        if 0xD7A3 < char_unicode or char_unicode < 0xAC00:\n",
    "            result.append(char)\n",
    "            continue\n",
    "\n",
    "        chosung_index = int((((char_unicode - 0xAC00) / 28) / 21) % 19)\n",
    "        joongsung_index = int(((char_unicode - 0xAC00) / 28) % 21)\n",
    "        jongsung_index = int((char_unicode - 0xAC00) % 28)\n",
    "        \n",
    "        chosung = CHOSUNG_LIST[chosung_index]\n",
    "        joongsung = JOONGSUNG_LISTS[joongsung_index]\n",
    "        jongsung = JONGSUNG_LIST[jongsung_index]\n",
    "        \n",
    "        # 종성이 없을 경우 end_char\n",
    "        if jongsung_index == 0:\n",
    "            jongsung = end_char\n",
    "        \n",
    "        result.append(chosung)\n",
    "        result.append(joongsung)\n",
    "        result.append(jongsung)\n",
    "\n",
    "    return \"\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment_df.reset_index(inplace=True)\n",
    "Comment_df.drop('index', axis=1, inplace=True)\n",
    "Comment_df = Comment_df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자모분리 후 저장\n",
    "Comment_df[0] = Comment_df[0].apply(lambda x: kor_decompose(x))\n",
    "Comment_df[0] = Comment_df[0].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ㅁㅣ_ㅇㅕㄴㅇㅣ_, ㄷㅔ_ㅂㅟ_ㅎㅏ_ㅁㅕㄴ, ㅁㅣ_ㅁㅗ_ㄹㅗ_, ㄷㅏ_, ㅆㅣㅂㅇ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ㅋㅠ_ㅂㅡ_ㅇㅑ_, ㅇㅏ_ㅇㅣ_ㄷㅡㄹ, ㅇㅖ_ㄴㅡㅇ, ㅈㅗㅁ, ㅁㅏㄶㅇㅣ_, ㄴㅐ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ㅋㅓㅁㅂㅐㄱㅎㅏㄹ, ㄸㅐ_, ㅁㅏ_ㄷㅏ_, ㅍㅏ_ㅌㅡ_ㅂㅜㄴㅂㅐ_ㄹㅡㄹ, ㅈㅏㄹ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ㅈㅣㄴㅅㅣㅁ, ㅇㅏ_ㅇㅣ_ㄷㅗㄹ, ㄴㅏ_ㅇㅗ_ㅁㅕㄴ, ㅎㅏㄴㄷㅜ_ㅁㅕㅇㅇㅡㄴ, ㅈ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ㅇㅘ_, ㅈㅗㄴㄴㅏ_, ㅇㅖ_ㅃㅡ_ㄷㅏ_, ㅇㅝㄴㄹㅐ_ㄷㅗ_, ㅇㅖ_ㅃㅓㅆㅈㅣ_ㅁ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219235</th>\n",
       "      <td>[ㅇ, ㅐㅈㅏ_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219236</th>\n",
       "      <td>[ㅆㅣ_ㅂㅜㄹㅇㅏㄹ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219237</th>\n",
       "      <td>[ㅈㅗㄴㅁㅏ_ㄴㅣ_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219238</th>\n",
       "      <td>[ㄱㅣ_ㅈㅣㅂㄴㅕㄴ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219239</th>\n",
       "      <td>[ㅂㅗ_ㅈㅣ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219239 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "1       [ㅁㅣ_ㅇㅕㄴㅇㅣ_, ㄷㅔ_ㅂㅟ_ㅎㅏ_ㅁㅕㄴ, ㅁㅣ_ㅁㅗ_ㄹㅗ_, ㄷㅏ_, ㅆㅣㅂㅇ...\n",
       "2       [ㅋㅠ_ㅂㅡ_ㅇㅑ_, ㅇㅏ_ㅇㅣ_ㄷㅡㄹ, ㅇㅖ_ㄴㅡㅇ, ㅈㅗㅁ, ㅁㅏㄶㅇㅣ_, ㄴㅐ...\n",
       "3       [ㅋㅓㅁㅂㅐㄱㅎㅏㄹ, ㄸㅐ_, ㅁㅏ_ㄷㅏ_, ㅍㅏ_ㅌㅡ_ㅂㅜㄴㅂㅐ_ㄹㅡㄹ, ㅈㅏㄹ,...\n",
       "4       [ㅈㅣㄴㅅㅣㅁ, ㅇㅏ_ㅇㅣ_ㄷㅗㄹ, ㄴㅏ_ㅇㅗ_ㅁㅕㄴ, ㅎㅏㄴㄷㅜ_ㅁㅕㅇㅇㅡㄴ, ㅈ...\n",
       "5       [ㅇㅘ_, ㅈㅗㄴㄴㅏ_, ㅇㅖ_ㅃㅡ_ㄷㅏ_, ㅇㅝㄴㄹㅐ_ㄷㅗ_, ㅇㅖ_ㅃㅓㅆㅈㅣ_ㅁ...\n",
       "...                                                   ...\n",
       "219235                                          [ㅇ, ㅐㅈㅏ_]\n",
       "219236                                        [ㅆㅣ_ㅂㅜㄹㅇㅏㄹ]\n",
       "219237                                        [ㅈㅗㄴㅁㅏ_ㄴㅣ_]\n",
       "219238                                        [ㄱㅣ_ㅈㅣㅂㄴㅕㄴ]\n",
       "219239                                            [ㅂㅗ_ㅈㅣ]\n",
       "\n",
       "[219239 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219239"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list로 변환\n",
    "Comment_list = list(Comment_df[0])\n",
    "len(Comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ㅁㅣ_ㅇㅕㄴㅇㅣ_',\n",
       "  'ㄷㅔ_ㅂㅟ_ㅎㅏ_ㅁㅕㄴ',\n",
       "  'ㅁㅣ_ㅁㅗ_ㄹㅗ_',\n",
       "  'ㄷㅏ_',\n",
       "  'ㅆㅣㅂㅇㅓ_ㅁㅓㄱㅇㅡㄹㅈㅜㄹ',\n",
       "  'ㅇㅏㄹㅇㅏㅆㄷㅏ_ㄴㅡㄴㄱㅓ_',\n",
       "  'ㅇㅙ_ㅋㅔ_',\n",
       "  'ㅇㅜㅅㄱㅕ_ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ'],\n",
       " ['ㅋㅠ_ㅂㅡ_ㅇㅑ_',\n",
       "  'ㅇㅏ_ㅇㅣ_ㄷㅡㄹ',\n",
       "  'ㅇㅖ_ㄴㅡㅇ',\n",
       "  'ㅈㅗㅁ',\n",
       "  'ㅁㅏㄶㅇㅣ_',\n",
       "  'ㄴㅐ_ㅂㅗ_ㄴㅐ_ㅈㅝ_ㄹㅏ_',\n",
       "  'ㅇㅗ_ㄴㅡㄹ',\n",
       "  'ㅇㅏ_ㅎㅕㅇ',\n",
       "  'ㄴㅓ_ㅁㅜ_',\n",
       "  'ㅈㅐ_ㅁㅣㅆㅇㅓㅆㄷㅏ_',\n",
       "  'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ'],\n",
       " ['ㅋㅓㅁㅂㅐㄱㅎㅏㄹ',\n",
       "  'ㄸㅐ_',\n",
       "  'ㅁㅏ_ㄷㅏ_',\n",
       "  'ㅍㅏ_ㅌㅡ_ㅂㅜㄴㅂㅐ_ㄹㅡㄹ',\n",
       "  'ㅈㅏㄹ',\n",
       "  'ㅁㅗㅅㅎㅏㄴㄷㅏ_ㄱㅗ_',\n",
       "  'ㅁㅝ_ㄹㅏ_ㅎㅏ_ㄴㅡㄴㄷㅔ_',\n",
       "  'ㄱㅡ_ㄹㅜㅂㅇㅔ_',\n",
       "  'ㅈㅓㄴㅅㅗ_ㅇㅕㄴㅇㅣ_',\n",
       "  'ㅇㅣㅆㄴㅡㄴ',\n",
       "  'ㄱㅓㅅㅁㅏㄴㅇㅡ_ㄹㅗ_ㄷㅗ_',\n",
       "  '',\n",
       "  'ㅋㅡㄴ',\n",
       "  'ㅎㅐㅇㅇㅜㄴㅇㅣㅁ',\n",
       "  'ㄷㅐ_ㅊㅔ_',\n",
       "  'ㅇㅓ_ㄸㅓㄴ',\n",
       "  'ㄱㅡ_ㄹㅜㅂㅇㅔ_',\n",
       "  'ㄹㅣ_ㄷㅓ_ㄱㅏ_',\n",
       "  'ㅍㅡ_ㄹㅗ_ㄷㅠ_ㅅㅣㅇ',\n",
       "  'ㅃㅜㄴㅁㅏㄴ',\n",
       "  'ㅇㅏ_ㄴㅣ_ㄹㅏ_',\n",
       "  'ㅁㅔㅁㅂㅓ_ㄷㅡㄹ',\n",
       "  'ㅇㅡㅁㅅㅐㄱ',\n",
       "  'ㅂㅏㄹㅇㅡㅁㄲㅏ_ㅈㅣ_',\n",
       "  'ㅅㅣㄴㄱㅕㅇㅆㅓ_ㅅㅓ_',\n",
       "  'ㄴㅗ_ㄹㅐ_ㄹㅡㄹ',\n",
       "  'ㅁㅏㄴㄷㅡㄹㅇㅓ_ㅈㅜ_ㄱㅗ_',\n",
       "  'ㅋㅓㅁㅂㅐㄱㅎㅏㄹㄸㅐ_',\n",
       "  'ㅁㅏ_ㄷㅏ_',\n",
       "  'ㅋㅓㄴㅅㅔㅂㅇㅡㄴ',\n",
       "  'ㅁㅐ_ㅂㅓㄴ',\n",
       "  'ㄷㅏ_ㄹㅡㄴㄷㅔ_',\n",
       "  'ㄸㅗ_',\n",
       "  'ㅁㅔㅁㅂㅓ_ㄷㅡㄹㅇㅣ_ㄹㅏㅇ',\n",
       "  'ㅇㅓ_ㅇㅜㄹㄹㅣ_ㄱㅔ_',\n",
       "  'ㅁㅏㄴㄷㅡㄹㅇㅓ_ㅈㅜ_ㄴㅑ_ㄱㅗ_',\n",
       "  'ㅈㅓㄴㅅㅗ_ㅇㅕㄴㅇㅡㄴ',\n",
       "  'ㅈㅣㄴㅉㅏ_',\n",
       "  'ㅊㅚ_ㄱㅗ_ㅇㅢ_',\n",
       "  'ㄹㅣ_ㄷㅓ_ㄷㅏ_',\n",
       "  'ㄱㅡ_ㄹㅣ_ㄱㅗ_',\n",
       "  'ㅈㅓㄴㅅㅗ_ㅇㅕㄴㅇㅢ_',\n",
       "  'ㅅㅡ_ㅋㅔ_ㅊㅣ_ㄹㅡㄹ',\n",
       "  'ㅇㅣㅆㄴㅡㄴ',\n",
       "  'ㄱㅡ_ㄷㅐ_ㄹㅗ_',\n",
       "  'ㅍㅛ_ㅎㅕㄴㅎㅐ_ㅈㅜ_ㄱㅗ_',\n",
       "  'ㄷㅟㅅㅂㅏㄷㅊㅣㅁㅎㅐ_ㅈㅜ_ㄴㅡㄴ',\n",
       "  'ㅁㅔㅁㅂㅓ_ㄷㅡㄹㅇㅣ_',\n",
       "  'ㅇㅣㅆㄱㅣ_ㅇㅔ_',\n",
       "  'ㅈㅣ_ㄱㅡㅁㅇㅢ_',\n",
       "  'ㅇㅏ_ㅇㅣ_ㄷㅡㄹㅇㅣ_',\n",
       "  'ㅇㅣㅆㄷㅏ_ㄱㅗ_',\n",
       "  'ㅅㅐㅇㄱㅏㄱㅎㅏㅁ'],\n",
       " ['ㅈㅣㄴㅅㅣㅁ',\n",
       "  'ㅇㅏ_ㅇㅣ_ㄷㅗㄹ',\n",
       "  'ㄴㅏ_ㅇㅗ_ㅁㅕㄴ',\n",
       "  'ㅎㅏㄴㄷㅜ_ㅁㅕㅇㅇㅡㄴ',\n",
       "  'ㅈㅗ_ㅇㅛㅇㅎㅏ_ㄱㅔ_',\n",
       "  'ㅈㅣ_ㄴㅏ_ㄱㅏㅆㄴㅡㄴㄷㅔ_',\n",
       "  'ㅎㅏㄴㅁㅕㅇㅎㅏㄴㅁㅕㅇㅇㅣ_',\n",
       "  'ㄷㅏ_',\n",
       "  'ㄴㅓ_ㅁㅜ_',\n",
       "  'ㅇㅜㅅㄱㅣㅁㅋㅋㅋㅋ',\n",
       "  'ㄱㅓ_ㄹㅡㄹ',\n",
       "  'ㅌㅏ_ㅅㅓㄴㅇㅣ_',\n",
       "  'ㅇㅓㅄㄴㅡㄴ',\n",
       "  'ㄹㅔ_ㅈㅓㄴㄷㅡ_ㅍㅕㄴㅇㅣ_ㅇㅓㅆㅇㅡㅁ'],\n",
       " ['ㅇㅘ_',\n",
       "  'ㅈㅗㄴㄴㅏ_',\n",
       "  'ㅇㅖ_ㅃㅡ_ㄷㅏ_',\n",
       "  'ㅇㅝㄴㄹㅐ_ㄷㅗ_',\n",
       "  'ㅇㅖ_ㅃㅓㅆㅈㅣ_ㅁㅏㄴ',\n",
       "  'ㅈㅓㅁㅈㅓㅁ',\n",
       "  'ㅂㅗㄴㅇㅣㄴㄷㅡㄹㅎㅏㄴㅌㅔ_',\n",
       "  'ㅇㅓ_ㅇㅜㄹㄹㅣ_ㄴㅡㄴ',\n",
       "  'ㅅㅡ_ㅌㅏ_ㅇㅣㄹ',\n",
       "  'ㅊㅏㅈㅇㅏ_ㄱㅏ_ㄴㅡㄴ',\n",
       "  'ㄷㅡㅅ',\n",
       "  'ㅇㅛ_ㅈㅡㅁㅇㅡㄴ',\n",
       "  'ㅇㅏ_ㅁㅜ_ㄹㅣ_',\n",
       "  'ㅇㅖ_ㅃㅓ_ㄷㅗ_',\n",
       "  'ㅅㅡ_ㅌㅏ_ㅇㅣㄹㄹㅣㅇ',\n",
       "  'ㄱㅐ_ㄸㅓㄱ',\n",
       "  'ㄱㅏㅌㅇㅡ_ㅁㅕㄴ',\n",
       "  'ㄴㅜㄴㅇㅔ_',\n",
       "  'ㅈㅏㄹ',\n",
       "  'ㅇㅏㄴ',\n",
       "  'ㄸㅢ_ㄷㅓㄴㄷㅔ_',\n",
       "  'ㅇㅏ_ㅇㅣ_ㄷㅡㄹㅇㅡㄴ',\n",
       "  'ㅈㅣㄴㅉㅏ_ㅈㅣㄴㅉㅏ_ㅈㅣㄴㅉㅏ_',\n",
       "  'ㄷㅏ_',\n",
       "  'ㅇㅖ_ㅃㅓ_',\n",
       "  '',\n",
       "  '',\n",
       "  'ㅇㅣ_ㄹㅓㄴ',\n",
       "  'ㅅㅐ_ㄹㅓㅁㄷㅡㄹㅇㅣ_',\n",
       "  'ㅇㅖ_ㄴㅡㅇㄱㅏㅁㅇㅣ_ㄹㅏㅇ',\n",
       "  'ㅅㅣㄹㄹㅕㄱㄲㅏ_ㅈㅣ_',\n",
       "  'ㄱㅏㅈㅊㅝㅆㄷㅏ_ㄴㅣ_',\n",
       "  'ㅇㅏㅍㅇㅡ_ㄹㅗ_',\n",
       "  'ㄷㅓ_',\n",
       "  'ㅈㅏㄹㄷㅙㅆㅇㅡ_ㅁㅕㄴ',\n",
       "  'ㅈㅗㅎㄱㅔㅆㅇㅡㅁ',\n",
       "  'ㅈㅣㄴㅉㅏ_ㄹㅜ_'],\n",
       " ['ㄴㅏㄴ',\n",
       "  'ㅈㅓ_ㅈㅏㄱㄱㅝㄴㅇㅡㄹ',\n",
       "  'ㅂㅏㄷㅇㅏ_ㅈㅔ_ㅇㅣㄹ',\n",
       "  'ㅁㅓㅅㅇㅣㅆㄱㅗ_',\n",
       "  'ㄱㅏㄴㅈㅣ_ㄴㅏ_ㄱㅗ_',\n",
       "  'ㄱㅐ_ㅉㅓㄴㄷㅏ_ㄱㅗ_',\n",
       "  'ㅅㅐㅇㄱㅏㄱㅎㅏㄴㄷㅏ_ㄹㅇ',\n",
       "  'ㅈㅠㄴㄴㅐ_',\n",
       "  'ㅁㅓ_ㅅㅣㅅㄷㅏ_',\n",
       "  'ㅂㅜ_ㄹㅓ_ㅇㅜㄴㄱㅓㅅㄷㅗ_',\n",
       "  'ㅂㅜ_ㄹㅓ_ㅇㅜㄴㄱㅓ_ㅈㅣ_ㅁㅏㄴ',\n",
       "  'ㅈㅗㄴㄱㅕㅇㅅㅡ_ㄹㅓㅂㄴㅔ_',\n",
       "  'ㅈㅣㄴㅉㅏ_',\n",
       "  'ㅠㅠ'],\n",
       " ['I',\n",
       "  'watch',\n",
       "  'this',\n",
       "  'video',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'times',\n",
       "  'already',\n",
       "  'even',\n",
       "  'though',\n",
       "  'it',\n",
       "  'doesnt',\n",
       "  'have',\n",
       "  'English',\n",
       "  'subs',\n",
       "  'I',\n",
       "  'just',\n",
       "  'love',\n",
       "  'seeing',\n",
       "  'them',\n",
       "  'all',\n",
       "  'in',\n",
       "  'variety',\n",
       "  'shows',\n",
       "  'I',\n",
       "  'love',\n",
       "  'seeing',\n",
       "  'Soyeon',\n",
       "  'happy',\n",
       "  'with',\n",
       "  'the',\n",
       "  'members',\n",
       "  ''],\n",
       " ['ㅁㅕㅊㄴㅕㄴㅁㅏㄴㅇㅔ_',\n",
       "  'ㅂㅗㄴㅂㅏㅇㅇㅡ_ㄹㅗ_',\n",
       "  'ㅈㅐ_ㅁㅣㅆㄱㅔ_ㅂㅘㅆㄷㅏ_ㅋㅋㅋㅋㅋ',\n",
       "  'ㅈㅣㄴㅉㅏ_',\n",
       "  'ㅇㅓ_ㄷㅣㄹㄱㅏ_ㄷㅡㄴ',\n",
       "  'ㅅㅣ_ㄲㅡ_ㄹㅓㅂㄱㅗ_',\n",
       "  'ㅆㅏ_ㅇㅜㅁㅍㅗㄱㅂㅏㄹㅇㅣㄴ',\n",
       "  'ㅇㅜㄹㅇㅐ_ㄱㅣ_ㄷㅓㄹㅋㅋㅋㅋ',\n",
       "  'ㅁㅐ_ㅅㅜㄴㄱㅏㄴㅋㅣㄹㅍㅗ_ㅇㅑ_',\n",
       "  'ㅇㅐ_ㄷㅡㄹㄷㅗ_',\n",
       "  'ㅈㅣㄴㅉㅏ_',\n",
       "  'ㄴㅏ_ㅇㅗ_ㄱㅗ_ㅅㅣㅍㅇㅓ_ㅎㅏ_ㄷㅓㄴ',\n",
       "  'ㅂㅏㅇㅅㅗㅇㅇㅣ_ㄹㅏ_',\n",
       "  'ㄱㅡ_ㄹㅓㄴㅈㅣ_',\n",
       "  'ㄷㅓ_',\n",
       "  'ㅅㅣㄴㄴㅏ_ㅅㅓ_',\n",
       "  'ㅈㅐ_ㅁㅣㅆㄱㅔ_ㅎㅏ_ㄱㅗ_ㅇㅗㄴㄷㅡㅅ'],\n",
       " ['ㅈㅣㄴㅉㅏ_',\n",
       "  'ㅇㅏ_ㅎㅕㅇ',\n",
       "  'ㄴㅏ_ㅇㅗ_ㄱㅣ_ㅁㅏㄴㅇㅡㄹ',\n",
       "  'ㄱㅣ_ㄷㅏ_ㄹㅕㅆㄴㅡㄴㄷㅔ_ㅇㅜ_ㄹㅣ_',\n",
       "  'ㄱㅣ_ㄷㅡㄹ',\n",
       "  'ㅈㅣㄴㅉㅏ_',\n",
       "  'ㅅㅓㅇㄱㅗㅇㅎㅐㅆㄷㅏ_ㅇㅏ_ㅇㅏ_ㅠㅠ1ㅅㅣ_ㄱㅏㄴ',\n",
       "  '30ㅂㅜㄴ',\n",
       "  'ㄴㅐ_ㄴㅐ_',\n",
       "  'ㅇㅣㅂㄱㅏ_',\n",
       "  'ㅁㅣ_ㅅㅗ_ㄱㅏ_',\n",
       "  'ㅅㅏ_ㄹㅏ_ㅈㅣ_ㅈㅣ_',\n",
       "  'ㅇㅏㄶㅇㅏㅆㄷㅏ_ㅇㅏ_ㅇㅣ_ㄷㅡㄹ',\n",
       "  'ㅇㅖ_ㄴㅡㅇㄱㅏㅁ',\n",
       "  'ㅁㅣ_ㅊㅕㅆㄱㅗ_',\n",
       "  'ㅁㅔㅁㅂㅓ_ㄷㅡㄹ',\n",
       "  'ㅋㅔ_ㅁㅣ_ㄷㅗ_',\n",
       "  'ㄴㅓ_ㅁㅜ_',\n",
       "  'ㅈㅗㅎㅇㅏㅆㅇㅡㅁㅋㅋㅋㅋㅋㅋㄷㅏ_ㅇㅡㅁㅇㅔ_',\n",
       "  'ㄸㅗ_',\n",
       "  'ㄴㅏ_ㅇㅘㅆㅇㅡ_ㅁㅕㄴ',\n",
       "  'ㅈㅗㅎㄱㅔㅆㄷㅏ_ㅇㅕㄴㅁㅏㄹㅁㅜ_ㄷㅐ_',\n",
       "  'ㄸㅐㅁㅇㅔ_',\n",
       "  'ㅎㅘㄹㄷㅗㅇ',\n",
       "  'ㄱㅣ_ㄱㅏㄴ',\n",
       "  'ㅉㅏㄼㅇㅏ_ㅅㅓ_',\n",
       "  'ㅇㅏ_ㅅㅟㅂㅈㅣ_ㅁㅏㄴ',\n",
       "  'ㄴㅏㅁㅇㅡㄴ',\n",
       "  'ㅎㅘㄹㄷㅗㅇㄷㅗ_',\n",
       "  'ㅎㅘ_ㅇㅣ_ㅌㅣㅇㅇㅏ_ㅇㅣ_ㄷㅡㄹ',\n",
       "  'ㅅㅏ_ㄹㅏㅇㅎㅏ_ㄱㅗ_',\n",
       "  'ㅎㅏㅇㅅㅏㅇ',\n",
       "  'ㅇㅡㅇㅇㅝㄴㅎㅏㄹㄱㅔ_'],\n",
       " ['ㅁㅣㄴㄴㅣ_',\n",
       "  'ㅇㅣ_ㅂㅓㄴ',\n",
       "  'ㅅㅡ_ㅌㅏ_ㅇㅣㄹㄹㅣㅇ',\n",
       "  'ㅊㅚ_ㄱㅗ_ㄱㅗ_',\n",
       "  'ㅅㅗ_ㅇㅕㄴㅇㅣ_',\n",
       "  'ㅈㅣㄴㅉㅏ_',\n",
       "  'ㅍㅡ_ㄹㅗ_ㄷㅠ_ㅅㅣㅇ',\n",
       "  'ㅎㅏ_ㄴㅡㄴ',\n",
       "  'ㅂㅓㅂ',\n",
       "  'ㄴㅏ_ㅇㅗㄴ',\n",
       "  'ㄱㅓ_',\n",
       "  'ㄴㅓ_ㅁㅜ_',\n",
       "  'ㅅㅐ_ㄹㅗㅂㄱㅗ_',\n",
       "  'ㅈㅗㅎㄱㅗ_',\n",
       "  'ㅋㅋㅋ',\n",
       "  'ㅁㅣ_ㅇㅕㄴㅇㅣ_',\n",
       "  'ㅊㅓ_ㅇㅡㅁㅇㅔ_',\n",
       "  'ㅅㅠ_ㅎㅘ_',\n",
       "  'ㅎㅠㅇㄴㅐ_ㄴㅐㄹ',\n",
       "  'ㄸㅐ_',\n",
       "  'ㄴㅓ_ㅁㅜ_',\n",
       "  'ㅇㅜㅅㄱㅣㅁ',\n",
       "  'ㅋㅋㅋㅋㅋㅋ']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fasttext input\n",
    "Comment_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [WordEmbedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(Comment_list, vector_size=50, window=2, min_count=3, workers=4, sg=1, min_n=3, max_n=6, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79489"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 79489\n",
    "len(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2011ㄴㅕㄴ', 0.9966644048690796),\n",
       " ('2014ㄴㅕㄴ', 0.9957617521286011),\n",
       " ('2021ㄴㅕㄴ', 0.9943724274635315),\n",
       " ('2017ㄴㅕㄴ', 0.9932236671447754),\n",
       " ('2022ㄴㅕㄴ', 0.992773711681366),\n",
       " ('2012ㄴㅕㄴ', 0.9915316104888916),\n",
       " ('2019ㄴㅕㄴ', 0.9905400276184082),\n",
       " ('2023ㄴㅕㄴ', 0.9902234077453613),\n",
       " ('2009ㄴㅕㄴ', 0.9900348782539368),\n",
       " ('2013ㄴㅕㄴ', 0.9894234538078308)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(kor_decompose(\"2022년\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅁㅜㄴㅅㅐ_ㄲㅣ_', 0.9885829091072083),\n",
       " ('ㅅㅂㅅㅐ_ㄲㅣ_', 0.9878286123275757),\n",
       " ('ㅉㅏㅇㄱㅐ_ㅅㅐ_ㄲㅣ_', 0.9875786304473877),\n",
       " ('ㅈㅟ_ㅅㅐ_ㄲㅣ_', 0.9867092967033386),\n",
       " ('ㅂㅅㅅㅐ_ㄲㅣ_', 0.9844736456871033),\n",
       " ('ㅄㅅㅐ_ㄲㅣ_', 0.9843753576278687),\n",
       " ('ㅆㅣㅂㅅㅐ_ㄲㅣ_', 0.9840155243873596),\n",
       " ('ㅇㅐ_ㅅㅐ_ㄲㅣ_', 0.9835335612297058),\n",
       " ('ㄲㅏㅇㅍㅐ_ㅅㅐ_ㄲㅣ_', 0.9834245443344116),\n",
       " ('ㅇㅑㅇㅋㅟ_ㅅㅐ_ㄲㅣ_', 0.9830461144447327)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비슷한 욕설이 출력됨\n",
    "model.wv.most_similar(kor_decompose(\"개새끼\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('17ㄴㅕㄴ', 0.9978621602058411),\n",
       " ('16ㄴㅕㄴ', 0.9973353743553162),\n",
       " ('19ㄴㅕㄴ', 0.9970005750656128),\n",
       " ('1945ㄴㅕㄴ', 0.9969555735588074),\n",
       " ('1965ㄴㅕㄴ', 0.9969369173049927),\n",
       " ('36ㄴㅕㄴ', 0.9969033002853394),\n",
       " ('08ㄴㅕㄴ', 0.9967043995857239),\n",
       " ('21ㄴㅕㄴ', 0.9965476989746094),\n",
       " ('09ㄴㅕㄴ', 0.9964456558227539),\n",
       " ('15ㄴㅕㄴ', 0.9964216351509094)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 욕설이 출력되지 않음\n",
    "model.wv.most_similar(kor_decompose(\"18년\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅅㅣ_ㅂㅏㄹㄹㅕㄴ', 0.9870353937149048),\n",
       " ('ㅆㅣ_ㅂㅏㄹㄴㅕㄴ', 0.9842144846916199),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄴㅗㅁ', 0.97516268491745),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄹㅗㅁ', 0.9726601839065552),\n",
       " ('ㅆㅣ_ㅂㅏㄹㄹㅕㄴ', 0.9715257287025452),\n",
       " ('ㄱㅐ_ㅆㅣ_ㅂㅏㄹㄴㅕㄴ', 0.9710908532142639),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄹㅓㅁ', 0.9685385823249817),\n",
       " ('ㅅㅣ_ㅂㅏㄹㅋㅋ', 0.9665188789367676),\n",
       " ('ㄱㅐ_ㅆㅣ_ㅂㅏㄹㄹㅕㄴ', 0.9623039364814758),\n",
       " ('ㅆㅣ_ㅂㅓㄹㄴㅕㄴ', 0.9610145092010498)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비슷한 욕설이 출력됨\n",
    "model.wv.most_similar(kor_decompose(\"시발년\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 저장\n",
    "model.save(\"./Fasttext.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "03aab4221eabb5b090947200f58522311c44e3968445c8816a77822b1318598f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
